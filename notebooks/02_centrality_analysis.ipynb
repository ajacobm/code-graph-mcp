{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b1c2344",
   "metadata": {},
   "source": [
    "## Section 1: Setup & Load Graph\n",
    "\n",
    "Load libraries and reconstruct the graph from Notebook 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1602ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from typing import Dict, List, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "import httpx\n",
    "import redis.asyncio as redis\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j.exceptions import ServiceUnavailable\n",
    "\n",
    "# Configure visualization\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ… Libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0cfdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment and initialize connections (same as Notebook 01)\n",
    "REDIS_URL = os.getenv('REDIS_URL', 'redis://redis:6379')\n",
    "MEMGRAPH_URL = os.getenv('MEMGRAPH_URL', 'bolt://memgraph:7687')\n",
    "BACKEND_API_URL = os.getenv('BACKEND_API_URL', 'http://code-graph-http:8000')\n",
    "\n",
    "class GraphConnections:\n",
    "    \"\"\"Manages connections to Redis, Memgraph, and Backend API\"\"\"\n",
    "    def __init__(self, redis_url: str, memgraph_url: str, api_url: str):\n",
    "        self.redis_url = redis_url\n",
    "        self.memgraph_url = memgraph_url\n",
    "        self.api_url = api_url\n",
    "        self.redis_client = None\n",
    "        self.memgraph_driver = None\n",
    "        self.http_client = None\n",
    "    \n",
    "    async def connect(self):\n",
    "        try:\n",
    "            self.redis_client = await redis.from_url(self.redis_url, decode_responses=True)\n",
    "            await self.redis_client.ping()\n",
    "            print(\"âœ… Redis connected\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  Redis connection failed: {e}\")\n",
    "        \n",
    "        try:\n",
    "            self.memgraph_driver = GraphDatabase.driver(self.memgraph_url)\n",
    "            with self.memgraph_driver.session() as session:\n",
    "                session.run(\"RETURN 1\").consume()\n",
    "            print(\"âœ… Memgraph connected\")\n",
    "        except ServiceUnavailable:\n",
    "            print(f\"âš ï¸  Memgraph not available\")\n",
    "            self.memgraph_driver = None\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  Memgraph connection failed: {e}\")\n",
    "            self.memgraph_driver = None\n",
    "        \n",
    "        self.http_client = httpx.AsyncClient(base_url=self.api_url)\n",
    "        print(\"âœ… HTTP client ready\")\n",
    "\n",
    "connections = GraphConnections(REDIS_URL, MEMGRAPH_URL, BACKEND_API_URL)\n",
    "loop = asyncio.new_event_loop()\n",
    "asyncio.set_event_loop(loop)\n",
    "loop.run_until_complete(connections.connect())\n",
    "\n",
    "print(\"\\nâœ… All systems initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be1a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph data\n",
    "async def get_all_nodes():\n",
    "    try:\n",
    "        response = await connections.http_client.get('/api/graph/nodes/search?limit=1000')\n",
    "        data = response.json()\n",
    "        return pd.DataFrame(data.get('results', []))\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching nodes: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "async def get_all_relationships():\n",
    "    try:\n",
    "        response = await connections.http_client.get('/api/graph/relationships?limit=5000')\n",
    "        data = response.json()\n",
    "        return data.get('results', [])\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching relationships: {e}\")\n",
    "        return []\n",
    "\n",
    "# Fetch data\n",
    "nodes_df = loop.run_until_complete(get_all_nodes())\n",
    "relationships = loop.run_until_complete(get_all_relationships())\n",
    "\n",
    "# Build NetworkX graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "if not nodes_df.empty:\n",
    "    for idx, row in nodes_df.iterrows():\n",
    "        G.add_node(row['name'], \n",
    "                   type=row.get('type'), \n",
    "                   file=row.get('file'),\n",
    "                   language=row.get('language'))\n",
    "    print(f\"âœ… Added {len(nodes_df)} nodes\")\n",
    "\n",
    "for rel in relationships:\n",
    "    if rel.get('source_name') in G and rel.get('target_name') in G:\n",
    "        G.add_edge(rel['source_name'], rel['target_name'], \n",
    "                   relationship_type=rel.get('relationship_type'))\n",
    "\n",
    "print(f\"âœ… Added {G.number_of_edges()} edges\")\n",
    "print(f\"\\nGraph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42466361",
   "metadata": {},
   "source": [
    "## Section 2: Degree Centrality\n",
    "\n",
    "Degree centrality measures how directly connected a node is to other nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6f225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate degree centrality\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "degree_df = pd.DataFrame.from_dict(degree_centrality, orient='index', columns=['degree_centrality'])\n",
    "degree_df = degree_df.sort_values('degree_centrality', ascending=False)\n",
    "\n",
    "print(\"ðŸŽ¯ Top 15 Nodes by Degree Centrality\\n\")\n",
    "print(degree_df.head(15).to_string())\n",
    "\n",
    "print(f\"\\nðŸ“Š Statistics:\")\n",
    "print(f\"   Mean: {degree_df['degree_centrality'].mean():.4f}\")\n",
    "print(f\"   Median: {degree_df['degree_centrality'].median():.4f}\")\n",
    "print(f\"   Std Dev: {degree_df['degree_centrality'].std():.4f}\")\n",
    "print(f\"   Max: {degree_df['degree_centrality'].max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5c1821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize degree centrality distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(degree_df['degree_centrality'], bins=50, color='#4F46E5', alpha=0.7)\n",
    "axes[0].set_xlabel('Degree Centrality', fontsize=11)\n",
    "axes[0].set_ylabel('Number of Nodes', fontsize=11)\n",
    "axes[0].set_title('Degree Centrality Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Top 20 nodes\n",
    "top_20_degree = degree_df.head(20)\n",
    "axes[1].barh(range(len(top_20_degree)), top_20_degree['degree_centrality'], color='#4F46E5')\n",
    "axes[1].set_yticks(range(len(top_20_degree)))\n",
    "axes[1].set_yticklabels(top_20_degree.index, fontsize=9)\n",
    "axes[1].set_xlabel('Degree Centrality', fontsize=11)\n",
    "axes[1].set_title('Top 20 Nodes by Degree Centrality', fontsize=12, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2704890",
   "metadata": {},
   "source": [
    "## Section 3: Betweenness Centrality\n",
    "\n",
    "Identifies nodes that act as bridges between different parts of the graph (bottlenecks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba53f07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate betweenness centrality\n",
    "print(\"â³ Computing betweenness centrality (may take a moment)...\")\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "\n",
    "betweenness_df = pd.DataFrame.from_dict(betweenness_centrality, orient='index', columns=['betweenness_centrality'])\n",
    "betweenness_df = betweenness_df.sort_values('betweenness_centrality', ascending=False)\n",
    "\n",
    "print(\"\\nðŸŽ¯ Top 15 Nodes by Betweenness Centrality (Bottlenecks)\\n\")\n",
    "print(betweenness_df.head(15).to_string())\n",
    "\n",
    "print(f\"\\nðŸ“Š Statistics:\")\n",
    "print(f\"   Mean: {betweenness_df['betweenness_centrality'].mean():.4f}\")\n",
    "print(f\"   Median: {betweenness_df['betweenness_centrality'].median():.4f}\")\n",
    "print(f\"   Max: {betweenness_df['betweenness_centrality'].max():.4f}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Insight: These functions are critical bridges in the call graph.\")\n",
    "print(\"   Modifying them affects many other functions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5690ceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize betweenness centrality\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(betweenness_df['betweenness_centrality'], bins=50, color='#EC4899', alpha=0.7)\n",
    "axes[0].set_xlabel('Betweenness Centrality', fontsize=11)\n",
    "axes[0].set_ylabel('Number of Nodes', fontsize=11)\n",
    "axes[0].set_title('Betweenness Centrality Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Top 20 nodes\n",
    "top_20_betweenness = betweenness_df[betweenness_df['betweenness_centrality'] > 0].head(20)\n",
    "axes[1].barh(range(len(top_20_betweenness)), top_20_betweenness['betweenness_centrality'], color='#EC4899')\n",
    "axes[1].set_yticks(range(len(top_20_betweenness)))\n",
    "axes[1].set_yticklabels(top_20_betweenness.index, fontsize=9)\n",
    "axes[1].set_xlabel('Betweenness Centrality', fontsize=11)\n",
    "axes[1].set_title('Top Bottleneck Functions', fontsize=12, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e80ed1",
   "metadata": {},
   "source": [
    "## Section 4: Closeness Centrality\n",
    "\n",
    "Measures average distance to all other nodes (how central a node is in terms of reachability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d220f627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For directed graphs, use weakly connected components\n",
    "print(\"â³ Computing closeness centrality...\")\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "\n",
    "closeness_df = pd.DataFrame.from_dict(closeness_centrality, orient='index', columns=['closeness_centrality'])\n",
    "closeness_df = closeness_df.sort_values('closeness_centrality', ascending=False)\n",
    "\n",
    "print(\"\\nðŸŽ¯ Top 15 Nodes by Closeness Centrality\\n\")\n",
    "print(closeness_df.head(15).to_string())\n",
    "\n",
    "print(f\"\\nðŸ“Š Statistics:\")\n",
    "print(f\"   Mean: {closeness_df['closeness_centrality'].mean():.4f}\")\n",
    "print(f\"   Median: {closeness_df['closeness_centrality'].median():.4f}\")\n",
    "print(f\"   Max: {closeness_df['closeness_centrality'].max():.4f}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Insight: Functions close to all others are good candidates for refactoring.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03395234",
   "metadata": {},
   "source": [
    "## Section 5: PageRank\n",
    "\n",
    "Identifies important nodes based on graph structure and incoming edges (like Google's PageRank algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244f99b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PageRank\n",
    "print(\"â³ Computing PageRank...\")\n",
    "pagerank = nx.pagerank(G)\n",
    "\n",
    "pagerank_df = pd.DataFrame.from_dict(pagerank, orient='index', columns=['pagerank'])\n",
    "pagerank_df = pagerank_df.sort_values('pagerank', ascending=False)\n",
    "\n",
    "print(\"\\nðŸŽ¯ Top 15 Nodes by PageRank\\n\")\n",
    "print(pagerank_df.head(15).to_string())\n",
    "\n",
    "print(f\"\\nðŸ“Š Statistics:\")\n",
    "print(f\"   Mean: {pagerank_df['pagerank'].mean():.6f}\")\n",
    "print(f\"   Median: {pagerank_df['pagerank'].median():.6f}\")\n",
    "print(f\"   Max: {pagerank_df['pagerank'].max():.6f}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Insight: High PageRank nodes are called by many other important nodes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec486fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PageRank\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(pagerank_df['pagerank'], bins=50, color='#8B5CF6', alpha=0.7)\n",
    "axes[0].set_xlabel('PageRank Score', fontsize=11)\n",
    "axes[0].set_ylabel('Number of Nodes', fontsize=11)\n",
    "axes[0].set_title('PageRank Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Top 20 nodes\n",
    "top_20_pagerank = pagerank_df.head(20)\n",
    "axes[1].barh(range(len(top_20_pagerank)), top_20_pagerank['pagerank'], color='#8B5CF6')\n",
    "axes[1].set_yticks(range(len(top_20_pagerank)))\n",
    "axes[1].set_yticklabels(top_20_pagerank.index, fontsize=9)\n",
    "axes[1].set_xlabel('PageRank Score', fontsize=11)\n",
    "axes[1].set_title('Top 20 Nodes by PageRank', fontsize=12, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1f9e0c",
   "metadata": {},
   "source": [
    "## Section 6: Compare All Centrality Measures\n",
    "\n",
    "Create a comprehensive comparison of all centrality metrics for the top nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7142921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all metrics\n",
    "centrality_combined = pd.DataFrame({\n",
    "    'degree': degree_df['degree_centrality'],\n",
    "    'betweenness': betweenness_df['betweenness_centrality'],\n",
    "    'closeness': closeness_df['closeness_centrality'],\n",
    "    'pagerank': pagerank_df['pagerank']\n",
    "})\n",
    "\n",
    "# Normalize for better comparison\n",
    "centrality_normalized = centrality_combined.copy()\n",
    "for col in centrality_normalized.columns:\n",
    "    centrality_normalized[col] = (centrality_normalized[col] - centrality_normalized[col].min()) / (centrality_normalized[col].max() - centrality_normalized[col].min())\n",
    "\n",
    "# Calculate average centrality\n",
    "centrality_normalized['avg_centrality'] = centrality_normalized.mean(axis=1)\n",
    "centrality_normalized = centrality_normalized.sort_values('avg_centrality', ascending=False)\n",
    "\n",
    "print(\"ðŸŽ¯ Top 20 Nodes - Normalized Centrality Scores\\n\")\n",
    "print(centrality_normalized.head(20).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e2035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze correlations between metrics\n",
    "correlation_matrix = centrality_combined.corr()\n",
    "\n",
    "print(\"\\nðŸ“Š Correlation Matrix Between Centrality Measures\\n\")\n",
    "print(correlation_matrix.to_string())\n",
    "\n",
    "# Visualize correlation\n",
    "plt.figure(figsize=(8, 6))\n",
    "import seaborn as sns\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0, \n",
    "            square=True, cbar_kws={'label': 'Correlation'})\n",
    "plt.title('Centrality Metrics Correlation', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Insight: High correlations mean metrics agree on importance.\")\n",
    "print(\"   Low correlations reveal different aspects of centrality.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92202bbe",
   "metadata": {},
   "source": [
    "## Section 7: Visualize Critical Nodes\n",
    "\n",
    "Create graph visualizations highlighting high-centrality nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c407176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 10 nodes by average centrality\n",
    "top_critical_nodes = centrality_normalized.head(10).index.tolist()\n",
    "\n",
    "# Create subgraph with critical nodes and their neighbors\n",
    "neighbors = set()\n",
    "for node in top_critical_nodes:\n",
    "    neighbors.update(G.predecessors(node))\n",
    "    neighbors.update(G.successors(node))\n",
    "\n",
    "subgraph_nodes = top_critical_nodes + list(neighbors)\n",
    "G_sub = G.subgraph(subgraph_nodes).copy()\n",
    "\n",
    "print(f\"ðŸ“Š Critical nodes subgraph:\")\n",
    "print(f\"   Nodes: {G_sub.number_of_nodes()}\")\n",
    "print(f\"   Edges: {G_sub.number_of_edges()}\")\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Layout\n",
    "pos = nx.spring_layout(G_sub, k=2, iterations=50, seed=42)\n",
    "\n",
    "# Node colors based on PageRank\n",
    "node_colors = [pagerank.get(node, 0) for node in G_sub.nodes()]\n",
    "\n",
    "# Node sizes based on degree centrality\n",
    "node_sizes = [degree_centrality.get(node, 0.1) * 3000 for node in G_sub.nodes()]\n",
    "\n",
    "# Draw network\n",
    "nx.draw_networkx_edges(G_sub, pos, edge_color='gray', alpha=0.3, arrows=True, \n",
    "                        arrowsize=15, arrowstyle='->', width=1.5)\n",
    "\n",
    "nodes = nx.draw_networkx_nodes(G_sub, pos, node_color=node_colors, node_size=node_sizes,\n",
    "                               cmap='YlOrRd', alpha=0.9)\n",
    "\n",
    "# Labels for critical nodes only\n",
    "labels = {node: node if node in top_critical_nodes else '' for node in G_sub.nodes()}\n",
    "nx.draw_networkx_labels(G_sub, pos, labels, font_size=9, font_weight='bold')\n",
    "\n",
    "plt.colorbar(nodes, label='PageRank', shrink=0.8)\n",
    "plt.title('Critical Functions and Dependencies', fontsize=16, fontweight='bold')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Critical node visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2146243f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated centrality analysis for identifying critical functions:\n",
    "\n",
    "1. âœ… **Degree Centrality** - Direct connectivity (hub functions)\n",
    "2. âœ… **Betweenness Centrality** - Bottleneck functions (bridges)\n",
    "3. âœ… **Closeness Centrality** - Central functions (average distance)\n",
    "4. âœ… **PageRank** - Importance based on incoming edges\n",
    "5. âœ… **Comparison** - Correlation analysis of all metrics\n",
    "6. âœ… **Visualization** - Critical node subgraph and dependencies\n",
    "\n",
    "### Key Takeaways:\n",
    "- **High degree + high betweenness**: Core library functions (high refactoring risk)\n",
    "- **High PageRank only**: Important but not central (good refactoring candidates)\n",
    "- **High closeness**: Hub functions (consider dependency injection)\n",
    "\n",
    "### Next Step:\n",
    "- **Notebook 03**: Community Detection (identify module boundaries)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
