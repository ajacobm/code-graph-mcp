{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf7cf73b",
   "metadata": {},
   "source": [
    "## Section 1: Setup & Load Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed07ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from typing import Dict, List, Set, Tuple\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "\n",
    "import httpx\n",
    "import redis.asyncio as redis\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7917c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize connections\n",
    "REDIS_URL = os.getenv('REDIS_URL', 'redis://redis:6379')\n",
    "MEMGRAPH_URL = os.getenv('MEMGRAPH_URL', 'bolt://memgraph:7687')\n",
    "BACKEND_API_URL = os.getenv('BACKEND_API_URL', 'http://code-graph-http:8000')\n",
    "\n",
    "class GraphConnections:\n",
    "    def __init__(self, redis_url: str, memgraph_url: str, api_url: str):\n",
    "        self.redis_url = redis_url\n",
    "        self.memgraph_url = memgraph_url\n",
    "        self.api_url = api_url\n",
    "        self.redis_client = None\n",
    "        self.memgraph_driver = None\n",
    "        self.http_client = None\n",
    "    \n",
    "    async def connect(self):\n",
    "        try:\n",
    "            self.redis_client = await redis.from_url(self.redis_url, decode_responses=True)\n",
    "            await self.redis_client.ping()\n",
    "            print(\"‚úÖ Redis connected\")\n",
    "        except Exception:\n",
    "            print(\"‚ö†Ô∏è  Redis unavailable\")\n",
    "        \n",
    "        try:\n",
    "            self.memgraph_driver = GraphDatabase.driver(self.memgraph_url)\n",
    "            with self.memgraph_driver.session() as session:\n",
    "                session.run(\"RETURN 1\").consume()\n",
    "            print(\"‚úÖ Memgraph connected\")\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è  Memgraph unavailable\")\n",
    "            self.memgraph_driver = None\n",
    "        \n",
    "        self.http_client = httpx.AsyncClient(base_url=self.api_url)\n",
    "        print(\"‚úÖ HTTP client ready\")\n",
    "\n",
    "connections = GraphConnections(REDIS_URL, MEMGRAPH_URL, BACKEND_API_URL)\n",
    "loop = asyncio.new_event_loop()\n",
    "asyncio.set_event_loop(loop)\n",
    "loop.run_until_complete(connections.connect())\n",
    "\n",
    "print(\"\\n‚úÖ Connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e7c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph data\n",
    "async def get_all_nodes():\n",
    "    try:\n",
    "        response = await connections.http_client.get('/api/graph/nodes/search?limit=1000')\n",
    "        return pd.DataFrame(response.json().get('results', []))\n",
    "    except Exception as e:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "async def get_all_relationships():\n",
    "    try:\n",
    "        response = await connections.http_client.get('/api/graph/relationships?limit=5000')\n",
    "        return response.json().get('results', [])\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "nodes_df = loop.run_until_complete(get_all_nodes())\n",
    "relationships = loop.run_until_complete(get_all_relationships())\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(nodes_df)} nodes, {len(relationships)} relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8f428b",
   "metadata": {},
   "source": [
    "## Section 2: Extract Entity Types\n",
    "\n",
    "Identify different types of entities in the codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bd0f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze entity types\n",
    "entity_types = nodes_df['type'].value_counts()\n",
    "\n",
    "print(\"üìä Entity Type Distribution:\\n\")\n",
    "print(entity_types.to_string())\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "entity_types.plot(kind='barh', ax=ax, color='#4F46E5')\n",
    "ax.set_xlabel('Count', fontsize=12)\n",
    "ax.set_ylabel('Entity Type', fontsize=12)\n",
    "ax.set_title('Code Entity Type Distribution', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aeaf33",
   "metadata": {},
   "source": [
    "## Section 3: Extract Domain Vocabulary\n",
    "\n",
    "Identify key naming patterns and domain concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0b10d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract terms from names using camelCase/snake_case splitting\n",
    "def split_name(name: str) -> List[str]:\n",
    "    \"\"\"Split camelCase and snake_case names into terms\"\"\"\n",
    "    # First split on underscore\n",
    "    parts = name.split('_')\n",
    "    \n",
    "    # Then split camelCase\n",
    "    terms = []\n",
    "    for part in parts:\n",
    "        # Insert space before capital letters (not at start)\n",
    "        spaced = re.sub(r'(?<!^)(?=[A-Z])', ' ', part)\n",
    "        terms.extend([t.lower() for t in spaced.split() if t])\n",
    "    \n",
    "    return [t for t in terms if len(t) > 2]  # Filter short terms\n",
    "\n",
    "# Extract all terms\n",
    "all_terms = []\n",
    "for name in nodes_df['name']:\n",
    "    all_terms.extend(split_name(name))\n",
    "\n",
    "# Count term frequency\n",
    "term_frequency = Counter(all_terms)\n",
    "\n",
    "print(\"üéØ Top 30 Domain Concepts (Most Frequent Terms):\\n\")\n",
    "for term, count in term_frequency.most_common(30):\n",
    "    print(f\"  {term:20s}: {count:3d} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38aa77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize term frequency\n",
    "top_terms = dict(term_frequency.most_common(15))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.barh(list(top_terms.keys()), list(top_terms.values()), color='#8B5CF6')\n",
    "ax.set_xlabel('Frequency', fontsize=12)\n",
    "ax.set_ylabel('Domain Concept', fontsize=12)\n",
    "ax.set_title('Top Domain Concepts in Codebase', fontsize=14, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca25c876",
   "metadata": {},
   "source": [
    "## Section 4: Entity by Language\n",
    "\n",
    "Analyze entity distribution across programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3625c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language distribution\n",
    "language_dist = nodes_df['language'].value_counts()\n",
    "\n",
    "print(\"üåç Language Distribution:\\n\")\n",
    "print(language_dist.to_string())\n",
    "\n",
    "# Entity type by language\n",
    "print(\"\\nüìä Entity Types by Language:\\n\")\n",
    "cross_tab = pd.crosstab(nodes_df['language'], nodes_df['type'])\n",
    "print(cross_tab.to_string())\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "language_dist.plot(kind='bar', ax=ax1, color='#EC4899')\n",
    "ax1.set_title('Entities by Language', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Count', fontsize=11)\n",
    "ax1.set_xlabel('Language', fontsize=11)\n",
    "\n",
    "cross_tab.plot(kind='bar', ax=ax2, stacked=True)\n",
    "ax2.set_title('Entity Types by Language', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Count', fontsize=11)\n",
    "ax2.set_xlabel('Language', fontsize=11)\n",
    "ax2.legend(title='Entity Type', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b762ca54",
   "metadata": {},
   "source": [
    "## Section 5: Relationship Patterns\n",
    "\n",
    "Analyze types of relationships in the codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dca4eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship type distribution\n",
    "rel_df = pd.DataFrame(relationships)\n",
    "\n",
    "if not rel_df.empty and 'relationship_type' in rel_df.columns:\n",
    "    rel_types = rel_df['relationship_type'].value_counts()\n",
    "    \n",
    "    print(\"üîó Relationship Type Distribution:\\n\")\n",
    "    print(rel_types.to_string())\n",
    "    \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    rel_types.plot(kind='pie', ax=ax, autopct='%1.1f%%', colors=plt.cm.Set3(range(len(rel_types))))\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_title('Relationship Types in Code Graph', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No relationship type data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949d6b88",
   "metadata": {},
   "source": [
    "## Section 6: Semantic Ontology Export\n",
    "\n",
    "Generate RDF-like semantic representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f5cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ontology representation\n",
    "ontology = {\n",
    "    \"entities\": {},\n",
    "    \"relationships\": [],\n",
    "    \"concepts\": {},\n",
    "    \"metadata\": {\n",
    "        \"total_entities\": len(nodes_df),\n",
    "        \"total_relationships\": len(relationships),\n",
    "        \"languages\": list(language_dist.index),\n",
    "        \"entity_types\": list(entity_types.index),\n",
    "        \"top_concepts\": dict(term_frequency.most_common(20))\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add entities\n",
    "for idx, row in nodes_df.iterrows():\n",
    "    entity_id = row['name']\n",
    "    ontology[\"entities\"][entity_id] = {\n",
    "        \"type\": row['type'],\n",
    "        \"language\": row.get('language'),\n",
    "        \"file\": row.get('file'),\n",
    "        \"terms\": split_name(row['name'])\n",
    "    }\n",
    "\n",
    "# Add relationships\n",
    "for rel in relationships:\n",
    "    ontology[\"relationships\"].append({\n",
    "        \"source\": rel.get('source_name'),\n",
    "        \"target\": rel.get('target_name'),\n",
    "        \"type\": rel.get('relationship_type')\n",
    "    })\n",
    "\n",
    "# Add concept hierarchy\n",
    "for concept, count in term_frequency.most_common(50):\n",
    "    ontology[\"concepts\"][concept] = {\n",
    "        \"frequency\": count,\n",
    "        \"entities\": [name for name in nodes_df['name'] if concept in split_name(name)]\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Ontology Generated\")\n",
    "print(f\"   Entities: {len(ontology['entities'])}\")\n",
    "print(f\"   Relationships: {len(ontology['relationships'])}\")\n",
    "print(f\"   Concepts: {len(ontology['concepts'])}\")\n",
    "\n",
    "# Export as JSON\n",
    "import json\n",
    "ontology_json = json.dumps(ontology, indent=2)\n",
    "print(f\"\\nüìÑ Ontology size: {len(ontology_json)} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0498fa",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook extracted domain ontology from the code graph:\n",
    "\n",
    "1. ‚úÖ **Entity Types** - Classes, functions, variables, modules\n",
    "2. ‚úÖ **Domain Vocabulary** - Key naming patterns and concepts\n",
    "3. ‚úÖ **Language Analysis** - Multi-language entity distribution\n",
    "4. ‚úÖ **Relationships** - Connection types and patterns\n",
    "5. ‚úÖ **Semantic Ontology** - RDF-like knowledge graph\n",
    "\n",
    "### Use Cases:\n",
    "- Auto-generate API documentation\n",
    "- Semantic code search\n",
    "- Domain model extraction\n",
    "- Knowledge management\n",
    "\n",
    "### Next Step:\n",
    "- **Notebook 06**: C4 Diagram Generation (visualize architecture)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
