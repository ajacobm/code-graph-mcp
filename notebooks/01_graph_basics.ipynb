{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "906971b2",
   "metadata": {},
   "source": [
    "# Graph Basics & Connections\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. **Setup & Connection** - Connect to the CodeNav backend API\n",
    "2. **Graph Statistics** - Explore the analyzed codebase structure\n",
    "3. **Node Exploration** - Search and filter nodes by type, language\n",
    "4. **NetworkX Analysis** - Build in-memory graphs for analysis\n",
    "5. **Degree Analysis** - Identify hubs and leaf nodes\n",
    "\n",
    "**Backend**: CodeNav API at http://localhost:8000\n",
    "**Analysis**: Real-time code graph queries with filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de615438",
   "metadata": {},
   "source": [
    "## Section 1: Setup & Connection\n",
    "\n",
    "Import libraries and connect to the CodeNav backend API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257419f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Data science libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "# Add utils to path\n",
    "sys.path.insert(0, str(Path.cwd() / 'utils'))\n",
    "from graph_client import GraphClient\n",
    "\n",
    "# Configure visualization\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39acdb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize client and connect to CodeNav API\n",
    "# Uses CODENAV_API_URL env var or defaults to localhost:8000\n",
    "client = GraphClient()\n",
    "await client.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b8a88",
   "metadata": {},
   "source": [
    "## Section 2: Graph Statistics\n",
    "\n",
    "Fetch graph statistics from the backend API to understand the codebase structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e7dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch graph statistics\n",
    "stats = await client.get_stats()\n",
    "\n",
    "print(\"üìä Graph Statistics:\")\n",
    "print(f\"   ‚Ä¢ Total Nodes: {stats.total_nodes}\")\n",
    "print(f\"   ‚Ä¢ Total Relationships: {stats.total_relationships}\")\n",
    "print(f\"   ‚Ä¢ Seam Count: {stats.seam_count}\")\n",
    "\n",
    "# Show language distribution\n",
    "if stats.languages:\n",
    "    print(\"\\nüìä Languages:\")\n",
    "    for lang, count in stats.languages.items():\n",
    "        print(f\"   ‚Ä¢ {lang}: {count} nodes\")\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(stats.languages.keys(), stats.languages.values(), color='#4F46E5')\n",
    "    plt.xlabel('Language', fontsize=12)\n",
    "    plt.ylabel('Node Count', fontsize=12)\n",
    "    plt.title('Node Distribution by Language', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show node type distribution\n",
    "if stats.node_types:\n",
    "    print(\"\\nüìä Node Types:\")\n",
    "    for ntype, count in sorted(stats.node_types.items(), key=lambda x: -x[1]):\n",
    "        print(f\"   ‚Ä¢ {ntype}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07503ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export graph with filtering (exclude tests and stdlib for cleaner view)\n",
    "data = await client.export_graph(\n",
    "    exclude_stdlib=True,\n",
    "    exclude_tests=True,\n",
    "    include_private=True,\n",
    "    limit=5000\n",
    ")\n",
    "\n",
    "# Convert to DataFrames\n",
    "nodes_df = pd.DataFrame(data.get('nodes', []))\n",
    "links_df = pd.DataFrame(data.get('links', []))\n",
    "\n",
    "print(f\"üì¶ Exported Graph:\")\n",
    "print(f\"   ‚Ä¢ Nodes: {len(nodes_df)}\")\n",
    "print(f\"   ‚Ä¢ Links: {len(links_df)}\")\n",
    "\n",
    "# Show filter stats if available\n",
    "filter_stats = data.get('stats', {}).get('filterStats', {})\n",
    "if filter_stats:\n",
    "    print(f\"\\nüîç Filter Statistics:\")\n",
    "    print(f\"   ‚Ä¢ Filtered by tests: {filter_stats.get('filtered_by_tests', 0)}\")\n",
    "    print(f\"   ‚Ä¢ Filtered by stdlib: {filter_stats.get('filtered_by_stdlib', 0)}\")\n",
    "\n",
    "# Show first few nodes\n",
    "if not nodes_df.empty:\n",
    "    print(\"\\nüìã Sample Nodes:\")\n",
    "    display_cols = [c for c in ['name', 'type', 'language', 'file'] if c in nodes_df.columns]\n",
    "    print(nodes_df[display_cols].head(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9ae8a3",
   "metadata": {},
   "source": [
    "## Section 3: Entry Points & Seams\n",
    "\n",
    "Explore detected entry points (CLI commands, HTTP handlers) and cross-language seams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ce335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get entry points\n",
    "entry_points = await client.get_entry_points(limit=20)\n",
    "\n",
    "print(\"üöÄ Entry Points (Top-level handlers):\\n\")\n",
    "if entry_points:\n",
    "    for i, ep in enumerate(entry_points[:10], 1):\n",
    "        name = ep.get('name', 'unknown')\n",
    "        ep_type = ep.get('type', ep.get('entry_type', 'unknown'))\n",
    "        file_path = ep.get('file', ep.get('location', {}).get('file_path', ''))\n",
    "        print(f\"{i:2d}. [{ep_type}] {name}\")\n",
    "        if file_path:\n",
    "            print(f\"       üìÅ {file_path}\")\n",
    "    print(f\"\\n‚úÖ Found {len(entry_points)} entry points\")\n",
    "else:\n",
    "    print(\"No entry points detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfef9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cross-language seams\n",
    "seams = await client.get_seams(limit=20)\n",
    "\n",
    "print(\"ü™° Cross-Language Seams:\\n\")\n",
    "if seams:\n",
    "    for i, seam in enumerate(seams[:10], 1):\n",
    "        source = seam.get('source', seam.get('source_name', 'unknown'))\n",
    "        target = seam.get('target', seam.get('target_name', 'unknown'))\n",
    "        seam_type = seam.get('type', seam.get('seam_type', 'seam'))\n",
    "        print(f\"{i:2d}. {source} ‚Üî {target} [{seam_type}]\")\n",
    "    print(f\"\\n‚úÖ Found {len(seams)} seams\")\n",
    "else:\n",
    "    print(\"No cross-language seams detected (single-language codebase)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a551e07",
   "metadata": {},
   "source": [
    "## Section 4: Building NetworkX Graph\n",
    "\n",
    "Create an in-memory NetworkX graph for local analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84027f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build NetworkX graph (excludes tests and stdlib by default)\n",
    "print(\"üî® Building NetworkX graph...\\n\")\n",
    "\n",
    "G = await client.build_networkx_graph(\n",
    "    exclude_stdlib=True,\n",
    "    exclude_tests=True,\n",
    "    directed=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Graph Statistics:\")\n",
    "print(f\"   ‚Ä¢ Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"   ‚Ä¢ Edges: {G.number_of_edges()}\")\n",
    "print(f\"   ‚Ä¢ Density: {nx.density(G):.4f}\")\n",
    "\n",
    "# Check connectivity\n",
    "if G.number_of_nodes() > 0:\n",
    "    weakly_connected = nx.number_weakly_connected_components(G)\n",
    "    print(f\"   ‚Ä¢ Weakly Connected Components: {weakly_connected}\")\n",
    "    \n",
    "    # Largest component\n",
    "    largest_cc = max(nx.weakly_connected_components(G), key=len)\n",
    "    print(f\"   ‚Ä¢ Largest Component Size: {len(largest_cc)} nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ffd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìà Degree Analysis\\n\")\n",
    "\n",
    "if G.number_of_nodes() > 0:\n",
    "    # In-degree distribution (how many functions call each function)\n",
    "    in_degrees = dict(G.in_degree())\n",
    "    top_called = sorted(in_degrees.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "    print(\"Top 10 Most Called (Highest In-Degree):\")\n",
    "    for func, degree in top_called:\n",
    "        name = G.nodes[func].get('name', func)\n",
    "        print(f\"   {name}: {degree} callers\")\n",
    "\n",
    "    # Out-degree distribution (how many functions each function calls)\n",
    "    out_degrees = dict(G.out_degree())\n",
    "    top_callers = sorted(out_degrees.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "    print(\"\\nTop 10 Most Calls (Highest Out-Degree):\")\n",
    "    for func, degree in top_callers:\n",
    "        name = G.nodes[func].get('name', func)\n",
    "        print(f\"   {name}: {degree} calls\")\n",
    "\n",
    "    # Visualize degree distributions\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # In-degree histogram\n",
    "    in_degree_values = [v for v in in_degrees.values() if v > 0]\n",
    "    if in_degree_values:\n",
    "        axes[0].hist(in_degree_values, bins=30, color='#4F46E5', alpha=0.7, edgecolor='white')\n",
    "        axes[0].set_xlabel('In-Degree (Callers)', fontsize=11)\n",
    "        axes[0].set_ylabel('Count', fontsize=11)\n",
    "        axes[0].set_title('In-Degree Distribution', fontsize=12, fontweight='bold')\n",
    "        axes[0].set_yscale('log')\n",
    "\n",
    "    # Out-degree histogram\n",
    "    out_degree_values = [v for v in out_degrees.values() if v > 0]\n",
    "    if out_degree_values:\n",
    "        axes[1].hist(out_degree_values, bins=30, color='#EC4899', alpha=0.7, edgecolor='white')\n",
    "        axes[1].set_xlabel('Out-Degree (Callees)', fontsize=11)\n",
    "        axes[1].set_ylabel('Count', fontsize=11)\n",
    "        axes[1].set_title('Out-Degree Distribution', fontsize=12, fontweight='bold')\n",
    "        axes[1].set_yscale('log')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\n‚úÖ Analysis complete\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Graph is empty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22367496",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. ‚úÖ **Connection Setup** - Connected to CodeNav API using modern async/await\n",
    "2. ‚úÖ **Graph Statistics** - Explored node counts, languages, and types\n",
    "3. ‚úÖ **Filtering** - Used exclude_tests and exclude_stdlib for cleaner graphs\n",
    "4. ‚úÖ **Entry Points** - Found CLI commands, HTTP handlers\n",
    "5. ‚úÖ **NetworkX Analysis** - Built in-memory graph for analysis\n",
    "6. ‚úÖ **Degree Analysis** - Identified hubs and leaf nodes\n",
    "\n",
    "### Next Notebooks:\n",
    "- **02**: Centrality Analysis (PageRank, betweenness)\n",
    "- **03**: Community Detection (Louvain, module boundaries)\n",
    "- **04**: Architectural Patterns (god objects, cycles, seams)\n",
    "- **05**: Ontology Extraction (domain vocabulary)\n",
    "- **06**: C4 Diagram Generation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codenav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
